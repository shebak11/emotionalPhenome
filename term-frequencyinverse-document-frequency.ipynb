{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['label', 'outputs', 'text', 'encoding', 'prediction'])\n",
      "64301\n",
      "128\n",
      "64301\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from re import split\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'encoding', 'label', 'outputs', 'prediction'])\n",
      "80\n",
      "64\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "data = pickle.load( open( \"emotype_v3.p\", \"rb\" ) ) \n",
    "print (data[0].keys())\n",
    "print (len(data))\n",
    "\n",
    "_,m = data[0]['encoding'].shape\n",
    "n = len(data)\n",
    "print (m)\n",
    "print (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cluster_dic = {'addiction':0, 'anxiety':1, 'autism':2, 'bipolar':3, 'conversation':4, 'depression':5,\n",
    " 'happy':6, 'schizophrenia':7}\n",
    "for i in range(len(data)):\n",
    "    data[i]['cluster'] = label_cluster_dic[data[i]['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text  = []\n",
    "for i in range(len(data)):\n",
    "    tmp = data[i]['text'].strip().lower()\n",
    "    all_text.append(split(\"[^a-zA-Z']+\", tmp))\n",
    "    \n",
    "print (len(all_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64301\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "for i in range(len(all_text)):\n",
    "    for j in all_text[i]:\n",
    "        if j and dic.get(j,-1)!= 0:\n",
    "            dic[j] = 0\n",
    "            \n",
    "print(len(dic.keys()))\n",
    "print(dic['you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( all_text, open( \"all_text.p\", \"wb\" ) )\n",
    "pickle.dump( dic, open( \"dic.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = list(dic.keys())\n",
    "word_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text_with_cluster(cluster):\n",
    "    out = []\n",
    "    for i in range(len(data)):\n",
    "        if data[i]['cluster'] == cluster:\n",
    "            out.append(split(\"[^a-zA-Z']+\", data[i]['text'].strip().lower() ))\n",
    "    return out\n",
    "def count_word_of_cluster(texts):\n",
    "    out_dic = dic.fromkeys(dic,0)\n",
    "    for text in texts:\n",
    "        for word in text:\n",
    "            if word: out_dic[word] += 1\n",
    "    return out_dic\n",
    "def get_cluster_vectors(word_list,dic_cluster):\n",
    "    out = []\n",
    "    for word in word_list:  \n",
    "        out.append(dic_cluster[word])\n",
    "    return out\n",
    "def extract_vectors(cluster):\n",
    "    text_cluster = find_text_with_cluster(cluster)\n",
    "    dic_cluster = count_word_of_cluster(text_cluster)\n",
    "    vector_cluster = get_cluster_vectors(word_list,dic_cluster)\n",
    "    return vector_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, blob):\n",
    "    '''computes \"term frequency\" which is the number of times a word appears in a document blob, \n",
    "       normalized by dividing by the total number of words in blob. \n",
    "       We use TextBlob for breaking up the text into words and getting the word counts.'''\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    '''returns the number of documents containing word. \n",
    "    A generator expression is passed to the sum() function.'''\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    '''computes \"inverse document frequency\" or how common a word is among all documents in bloblist. \n",
    "       The more common a word is, the lower its idf. \n",
    "       We take the ratio of the total number of documents to the number of documents containing word, \n",
    "       then take the log of that. Add 1 to the divisor to prevent division by zero.'''\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    ''' computes the TF-IDF score. It's the product of tf and idf.'''\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: one, TF-IDF: 0.13516\n",
      "\tWord: two, TF-IDF: 0.0\n",
      "Top words in document 2\n",
      "\tWord: two, TF-IDF: 0.0\n",
      "\tWord: four, TF-IDF: 0.0\n",
      "Top words in document 3\n",
      "\tWord: five, TF-IDF: 0.13516\n",
      "\tWord: four, TF-IDF: 0.0\n"
     ]
    }
   ],
   "source": [
    "document1 = tb(\"one two three\")\n",
    "\n",
    "document2 = tb(\"two three four\")\n",
    "\n",
    "document3 = tb(\"three four five\")\n",
    "\n",
    "bloblist = [document1, document2, document3]\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:2]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "blob =  tb(\"one two three\")\n",
    "tf('one', blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_containing('two', bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2876820724517809"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf('three', bloblist) # log (3/(1+2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2876820724517809"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(3/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addiction\n",
      "anxiety\n",
      "autism\n",
      "bipolar\n",
      "conversation\n",
      "depression\n",
      "happy\n",
      "schizophrenia\n"
     ]
    }
   ],
   "source": [
    "bloblist = []\n",
    "diagnosis = []\n",
    "for cluster in list(label_cluster_dic.keys()):\n",
    "    print(cluster)\n",
    "    diagnosis.append(cluster)\n",
    "    cluster_text = find_text_with_cluster(label_cluster_dic[cluster])\n",
    "    list_of_posts = []\n",
    "    for post in cluster_text:\n",
    "        list_of_posts.append(' '.join(post))\n",
    "    big_string = tb(' '.join(list_of_posts))\n",
    "    bloblist.append(big_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1,addiction\n",
      "\tWord: kick, TF-IDF: 0.00865\n",
      "\tWord: fent, TF-IDF: 0.00576\n",
      "\tWord: puff, TF-IDF: 0.00576\n",
      "\tWord: pot, TF-IDF: 0.00576\n",
      "\tWord: caused, TF-IDF: 0.00576\n",
      "Top words in document 2,anxiety\n",
      "\tWord: shit, TF-IDF: 0.00825\n",
      "\tWord: public, TF-IDF: 0.00825\n",
      "\tWord: ven, TF-IDF: 0.00825\n",
      "\tWord: anxiety, TF-IDF: 0.00778\n",
      "\tWord: nauseous, TF-IDF: 0.0055\n",
      "Top words in document 3,autism\n",
      "\tWord: radiohead, TF-IDF: 0.00872\n",
      "\tWord: asperger, TF-IDF: 0.00872\n",
      "\tWord: awkward, TF-IDF: 0.00872\n",
      "\tWord: wants, TF-IDF: 0.00872\n",
      "\tWord: he, TF-IDF: 0.00591\n",
      "Top words in document 4,bipolar\n",
      "\tWord: bpd, TF-IDF: 0.00947\n",
      "\tWord: bipolar, TF-IDF: 0.00947\n",
      "\tWord: brain, TF-IDF: 0.00632\n",
      "\tWord: fog, TF-IDF: 0.00632\n",
      "\tWord: openly, TF-IDF: 0.00632\n",
      "Top words in document 5,conversation\n",
      "\tWord: agent, TF-IDF: 0.01132\n",
      "\tWord: mozart, TF-IDF: 0.00849\n",
      "\tWord: asks, TF-IDF: 0.00849\n",
      "\tWord: brit, TF-IDF: 0.00849\n",
      "\tWord: he, TF-IDF: 0.00576\n",
      "Top words in document 6,depression\n",
      "\tWord: one, TF-IDF: 0.0069\n",
      "\tWord: leave, TF-IDF: 0.00586\n",
      "\tWord: fucking, TF-IDF: 0.00552\n",
      "\tWord: even, TF-IDF: 0.00552\n",
      "\tWord: over, TF-IDF: 0.00552\n",
      "Top words in document 7,happy\n",
      "\tWord: we, TF-IDF: 0.00832\n",
      "\tWord: great, TF-IDF: 0.00832\n",
      "\tWord: working, TF-IDF: 0.00588\n",
      "\tWord: maybe, TF-IDF: 0.00555\n",
      "\tWord: seems, TF-IDF: 0.00555\n",
      "Top words in document 8,schizophrenia\n",
      "\tWord: first, TF-IDF: 0.00908\n",
      "\tWord: occasionally, TF-IDF: 0.00908\n",
      "\tWord: looked, TF-IDF: 0.00642\n",
      "\tWord: schizophrenia, TF-IDF: 0.00605\n",
      "\tWord: psychosis, TF-IDF: 0.00605\n"
     ]
    }
   ],
   "source": [
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {},{}\".format(i + 1, diagnosis[i]))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:5]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
