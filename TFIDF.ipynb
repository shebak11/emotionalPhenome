{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from re import split\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'outputs', 'label', 'encoding', 'prediction'])\n",
      "800\n",
      "128\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "data = pickle.load( open( \"emotype_v10_val.p\", \"rb\" ) ) \n",
    "print (data[0].keys())\n",
    "print (len(data))\n",
    "\n",
    "_,m = data[0]['encoding'].shape\n",
    "n = len(data)\n",
    "print (m)\n",
    "print (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cluster_dic = {'addiction':0, 'anxiety':1, 'autism':2, 'bipolar':3, 'conversation':4, 'depression':5,\n",
    " 'happy':6, 'schizophrenia':7}\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i]['cluster'] = label_cluster_dic[data[i]['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text_with_cluster(cluster):\n",
    "    out = []\n",
    "    for i in range(len(data)):\n",
    "        if data[i]['cluster'] == cluster:\n",
    "            out.append(split(\"[^a-zA-Z']+\", data[i]['text'].strip().lower() ))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, blob):\n",
    "    '''computes \"term frequency\" which is the number of times a word appears in a document blob, \n",
    "       normalized by dividing by the total number of words in blob. \n",
    "       We use TextBlob for breaking up the text into words and getting the word counts.'''\n",
    "    return blob.words.count(word) / len(blob.words)\n",
    "\n",
    "def n_containing(word, bloblist):\n",
    "    '''returns the number of documents containing word. \n",
    "    A generator expression is passed to the sum() function.'''\n",
    "    return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "def idf(word, bloblist):\n",
    "    '''computes \"inverse document frequency\" or how common a word is among all documents in bloblist. \n",
    "       The more common a word is, the lower its idf. \n",
    "       We take the ratio of the total number of documents to the number of documents containing word, \n",
    "       then take the log of that. Add 1 to the divisor to prevent division by zero.'''\n",
    "    return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "def tfidf(word, blob, bloblist):\n",
    "    ''' computes the TF-IDF score. It's the product of tf and idf.'''\n",
    "    return tf(word, blob) * idf(word, bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: one, TF-IDF: 0.13516\n",
      "\tWord: two, TF-IDF: 0.0\n",
      "Top words in document 2\n",
      "\tWord: two, TF-IDF: 0.0\n",
      "\tWord: four, TF-IDF: 0.0\n",
      "Top words in document 3\n",
      "\tWord: five, TF-IDF: 0.13516\n",
      "\tWord: four, TF-IDF: 0.0\n"
     ]
    }
   ],
   "source": [
    "document1 = tb(\"one two three\")\n",
    "\n",
    "document2 = tb(\"two three four\")\n",
    "\n",
    "document3 = tb(\"three four five\")\n",
    "\n",
    "bloblist = [document1, document2, document3]\n",
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:2]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "blob =  tb(\"one two three\")\n",
    "tf('one', blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_containing('two', bloblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2876820724517809"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf('three', bloblist) # log (3/(1+2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2876820724517809"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(3/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addiction\n",
      "anxiety\n",
      "autism\n",
      "bipolar\n",
      "conversation\n",
      "depression\n",
      "happy\n",
      "schizophrenia\n"
     ]
    }
   ],
   "source": [
    "bloblist = []\n",
    "diagnosis = []\n",
    "for cluster in list(label_cluster_dic.keys()):\n",
    "    print(cluster)\n",
    "    diagnosis.append(cluster)\n",
    "    cluster_text = find_text_with_cluster(label_cluster_dic[cluster])\n",
    "    list_of_posts = []\n",
    "    for post in cluster_text:\n",
    "        list_of_posts.append(' '.join(post))\n",
    "    big_string = tb(' '.join(list_of_posts))\n",
    "    bloblist.append(big_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1,addiction\n",
      "\tWord: oxy, TF-IDF: 0.00258\n",
      "\tWord: heroin, TF-IDF: 0.00211\n",
      "\tWord: opiates, TF-IDF: 0.00211\n",
      "\tWord: dope, TF-IDF: 0.00187\n",
      "\tWord: addiction, TF-IDF: 0.00164\n",
      "Top words in document 2,anxiety\n",
      "\tWord: panic, TF-IDF: 0.00127\n",
      "\tWord: attacks, TF-IDF: 0.00116\n",
      "\tWord: interview, TF-IDF: 0.00116\n",
      "\tWord: attack, TF-IDF: 0.00082\n",
      "\tWord: class, TF-IDF: 0.00081\n",
      "Top words in document 3,autism\n",
      "\tWord: autism, TF-IDF: 0.00398\n",
      "\tWord: aspergers, TF-IDF: 0.00199\n",
      "\tWord: asperger, TF-IDF: 0.00174\n",
      "\tWord: autistic, TF-IDF: 0.00141\n",
      "\tWord: nts, TF-IDF: 0.00124\n",
      "Top words in document 4,bipolar\n",
      "\tWord: bipolar, TF-IDF: 0.00363\n",
      "\tWord: bpd, TF-IDF: 0.00363\n",
      "\tWord: server, TF-IDF: 0.00204\n",
      "\tWord: hypomanic, TF-IDF: 0.00181\n",
      "\tWord: discord, TF-IDF: 0.00136\n",
      "Top words in document 5,conversation\n",
      "\tWord: replies, TF-IDF: 0.00206\n",
      "\tWord: ice, TF-IDF: 0.00154\n",
      "\tWord: cream, TF-IDF: 0.00109\n",
      "\tWord: agent, TF-IDF: 0.00103\n",
      "\tWord: penguin, TF-IDF: 0.00103\n",
      "Top words in document 6,depression\n",
      "\tWord: lonely, TF-IDF: 0.00079\n",
      "\tWord: didn, TF-IDF: 0.00079\n",
      "\tWord: cried, TF-IDF: 0.00067\n",
      "\tWord: deserve, TF-IDF: 0.00067\n",
      "\tWord: exhausted, TF-IDF: 0.00063\n",
      "Top words in document 7,happy\n",
      "\tWord: midnight, TF-IDF: 0.00124\n",
      "\tWord: utc, TF-IDF: 0.00124\n",
      "\tWord: picture, TF-IDF: 0.00117\n",
      "\tWord: succeed, TF-IDF: 0.00103\n",
      "\tWord: list, TF-IDF: 0.00102\n",
      "Top words in document 8,schizophrenia\n",
      "\tWord: voices, TF-IDF: 0.00339\n",
      "\tWord: schizophrenia, TF-IDF: 0.00222\n",
      "\tWord: psychosis, TF-IDF: 0.00183\n",
      "\tWord: abilify, TF-IDF: 0.00148\n",
      "\tWord: schizophrenic, TF-IDF: 0.00131\n"
     ]
    }
   ],
   "source": [
    "for i, blob in enumerate(bloblist):\n",
    "    print(\"Top words in document {},{}\".format(i + 1, diagnosis[i]))\n",
    "    scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:5]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
